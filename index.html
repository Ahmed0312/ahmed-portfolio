<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Ahmed Alam - Lead Data Engineer with 8+ years of experience in cloud-based data engineering projects">
    <meta name="keywords" content="Data Engineer, AWS, Spark, Airflow, Python, Cloud Computing">
    <title>Ahmed Alam - Lead Data Engineer</title>
    
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600;700&display=swap" rel="stylesheet">
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Custom CSS -->
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <a href="#home">Ahmed Alam</a>
            </div>
            <div class="nav-menu" id="nav-menu">
                <a href="#home" class="nav-link">Home</a>
                <a href="#skills" class="nav-link">Skills</a>
                <a href="#experience" class="nav-link">Experience</a>
                <a href="#certifications" class="nav-link">Certifications</a>
                <a href="#projects" class="nav-link">Projects</a>
                <a href="#contact" class="nav-link">Contact</a>
            </div>
            <div class="hamburger" id="hamburger">
                <span class="bar"></span>
                <span class="bar"></span>
                <span class="bar"></span>
            </div>
        </div>
    </nav>

    <!-- Hero/Home Section -->
    <section id="home" class="hero">
        <div class="container">
            <div class="hero-content">
                <div class="hero-text">
                    <h1 class="hero-title">Ahmed Alam</h1>
                    <h2 class="hero-subtitle">Lead Data Engineer</h2>
                    <p class="hero-description">
                        Experienced Lead Data Engineer with 8+ years of success in designing and delivering enterprise-scale data solutions 
                        across banking and pharmaceutical domains for US clients. Skilled in architecting modern data platforms, leading cross-functional teams, 
                        and collaborating with business stakeholders to translate complex requirements into scalable, cloud-native data solutions. 
                        Hands-on expertise in Big Data (Spark, Hadoop), AWS (EMR, Redshift, Lambda, MWAA), and automation using NiFi, 
                        Airflow, and Python. Proven ability to deliver data lakes, ingestion pipelines, and BI systems with performance, governance, 
                        and cost optimization.
                    </p>
                    <div class="hero-buttons">
                        <a href="#contact" class="btn btn-primary">Get In Touch</a>
                        <a href="resume.pdf" download class="btn btn-secondary">
                            <i class="fas fa-download"></i> Download Resume
                        </a>
                    </div>
                </div>
                <div class="hero-image">
                    <div class="profile-picture">
                        <img src="Ahmed_profile_1753010004318.jpeg" alt="Ahmed Alam - Lead Data Engineer">
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Skills Section -->
    <section id="skills" class="skills">
        <div class="container">
            <h2 class="section-title">Technical Skills</h2>
            <div class="skills-grid">
                <div class="skill-category">
                    <h3><i class="fas fa-database"></i> Big Data</h3>
                    <ul>
                        <li><i class="fas fa-fire"></i> Apache Spark</li>
                        <li><i class="fas fa-server"></i> Hadoop</li>
                        <li><i class="fas fa-chart-line"></i> Databricks</li>
                        <li><i class="fas fa-search"></i> Elasticsearch</li>
                        <li><i class="fas fa-table"></i> Apache Hive</li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h3><i class="fas fa-cloud"></i> Cloud Platforms</h3>
                    <ul>
                        <li><i class="fab fa-aws"></i> Amazon Web Services (AWS)</li>
                        <li><i class="fas fa-layer-group"></i> AWS EMR</li>
                        <li><i class="fas fa-hdd"></i> AWS S3</li>
                        <li><i class="fas fa-bolt"></i> AWS Lambda</li>
                        <li><i class="fas fa-bell"></i> AWS SNS</li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h3><i class="fas fa-code"></i> Programming</h3>
                    <ul>
                        <li><i class="fab fa-python"></i> Python</li>
                        <li><i class="fas fa-fire"></i> PySpark</li>
                        <li><i class="fas fa-database"></i> SQL</li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h3><i class="fas fa-chart-bar"></i> Data Warehousing/BI</h3>
                    <ul>
                        <li><i class="fas fa-stream"></i> Apache Airflow</li>
                        <li><i class="fas fa-snowflake"></i> Snowflake</li>
                        <li><i class="fas fa-warehouse"></i> Redshift</li>
                        <li><i class="fas fa-chart-pie"></i> Power BI</li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h3><i class="fas fa-exchange-alt"></i> Integration</h3>
                    <ul>
                        <li><i class="fas fa-project-diagram"></i> Apache NiFi</li>
                        <li><i class="fas fa-plug"></i> REST APIs</li>
                        <li><i class="fas fa-arrows-alt-h"></i> ETL/ELT</li>
                        <li><i class="fas fa-sitemap"></i> Data Pipelines</li>
                        <li><i class="fas fa-cubes"></i> Microservices</li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h3><i class="fas fa-cogs"></i> DevOps</h3>
                    <ul>
                        <li><i class="fab fa-docker"></i> Docker</li>
                        <li><i class="fas fa-hammer"></i> Jenkins</li>
                        <li><i class="fab fa-git-alt"></i> Git</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Experience Section -->
    <section id="experience" class="experience">
        <div class="container">
            <h2 class="section-title">Professional Experience</h2>
            <div class="timeline">
                <div class="timeline-item">
                    <div class="timeline-date">July 2021 - Present</div>
                    <div class="timeline-content">
                        <h3>Principal Consultant Data Analytics</h3>
                        <h4>Systems Limited, Karachi</h4>
                        <ul>
                            <li>Processed 5TB+ daily using Amazon EMR & Apache Spark, improving query speeds by 40%</li>
                            <li>Designed and implemented scalable data ingestion pipelines using Apache NiFi, reducing latency by 30%</li>
                            <li>Automated data workflows with AWS MWAA (Airflow), improving task execution efficiency by 50%</li>
                            <li>Optimized costs using AWS Lambda serverless architecture, reducing cloud expenses by 20%</li>
                            <li>Designed an event-based pipeline for automated Redshift data warehouse loads, enhancing data availability</li>
                            <li>Developed custom Python-based API integrations, streamlining data acquisition from multiple external sources</li>
                            <li>Implemented CI/CD pipelines using Jenkins, reducing deployment time by 35%</li>
                            <li>Led requirement gathering sessions with clients to define business needs and data solutions</li>
                            <li>Managed and mentored a team of data engineers, ensuring project deliverables were met efficiently</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">Feb 2020 - July 2021</div>
                    <div class="timeline-content">
                        <h3>Data Engineer</h3>
                        <h4>Habib Bank Limited, Karachi</h4>
                        <ul>
                            <li>Developed Hadoop-based ETL pipelines, improving data load performance by 45%</li>
                            <li>Designed a Snowflake-based dimensional model, integrating data from multiple banking systems</li>
                            <li>Ensured data model consistency and referential integrity across multiple layers (ODS, staging, and DWH)</li>
                            <li>Worked closely with business teams to understand reporting needs and translate them into optimized DWH structures</li>
                            <li>Automated SSRS reports and FTP deliveries, reducing manual workload by 50%</li>
                            <li>Built real-time data pipelines using Spark Structured Streaming for continuous data processing</li>
                            <li>Built custom reporting solutions that improved visibility into key banking metrics</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">July 2019 - Feb 2020</div>
                    <div class="timeline-content">
                        <h3>Implementation Consultant</h3>
                        <h4>Centegy Technologies, Karachi</h4>
                        <ul>
                            <li>Played a key role in requirement analysis, implementation, development, and production phases</li>
                            <li>Established and maintained data warehouses, translating business needs into technical specifications</li>
                            <li>Designed, built, and deployed BI solutions</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">Sept 2018 - June 2019</div>
                    <div class="timeline-content">
                        <h3>Data Engineer</h3>
                        <h4>Sybrid Private Limited - A Lakson Group Company, Karachi</h4>
                        <ul>
                            <li>Optimized existing ETL processes, reducing execution time by 30%</li>
                            <li>Built a restaurant management data warehouse, integrating POS and inventory systems</li>
                            <li>Integrated Active Directory (AD) with SQL Server for enhanced authentication & security</li>
                        </ul>
                    </div>
                </div>
                <div class="timeline-item">
                    <div class="timeline-date">Aug 2017 - Sept 2018</div>
                    <div class="timeline-content">
                        <h3>BI Developer</h3>
                        <h4>Viftech Solutions, Karachi</h4>
                        <ul>
                            <li>Developed ETL processes and data warehouse for mortgage-based systems, automating data transformations</li>
                            <li>Created SSRS reports and SQL Agent jobs, enhancing data visibility</li>
                            <li>Designed interactive dashboards for better business insights</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Certifications Section -->
    <section id="certifications" class="certifications">
        <div class="container">
            <h2 class="section-title">Certifications</h2>
            <div class="cert-grid">
                <div class="cert-card">
                    <div class="cert-icon">
                        <i class="fab fa-microsoft"></i>
                    </div>
                    <h3>Azure Data Fundamentals</h3>
                    <p>DP-900</p>
                    <span class="cert-badge">Microsoft Azure</span>
                </div>
                <div class="cert-card">
                    <div class="cert-icon">
                        <i class="fab fa-microsoft"></i>
                    </div>
                    <h3>Azure Data Engineer Associate</h3>
                    <p>DP-203</p>
                    <span class="cert-badge">Microsoft Azure</span>
                </div>
                <div class="cert-card">
                    <div class="cert-icon">
                        <i class="fab fa-python"></i>
                    </div>
                    <h3>Introduction to Python</h3>
                    <p>Programming Fundamentals</p>
                    <span class="cert-badge">Python</span>
                </div>
                <div class="cert-card">
                    <div class="cert-icon">
                        <i class="fas fa-fire"></i>
                    </div>
                    <h3>Introduction to PySpark</h3>
                    <p>Big Data Processing</p>
                    <span class="cert-badge">PySpark</span>
                </div>
            </div>
        </div>
    </section>

    <!-- Projects Section -->
    <section id="projects" class="projects">
        <div class="container">
            <h2 class="section-title">Featured Projects</h2>
            <div class="projects-grid">
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-fire"></i>
                    </div>
                    <h3>Spark Based Ingestion Framework</h3>
                    <p>Developed an event-based architecture for data ingestion using Spark, providing scalable and efficient data processing capabilities.</p>
                    <div class="project-tech">
                        <span>AWS EMR</span>
                        <span>Lambda</span>
                        <span>S3</span>
                        <span>MWAA</span>
                        <span>SNS</span>
                        <span>Redshift</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-users"></i>
                    </div>
                    <h3>Veeva Salesforce CRM Development</h3>
                    <p>Led development for both US and European regions, integrating CRM data into Data Lake and establishing Data Warehouse on Redshift for business reporting.</p>
                    <div class="project-tech">
                        <span>RTS</span>
                        <span>AWS EMR</span>
                        <span>S3</span>
                        <span>Lambda</span>
                        <span>Redshift</span>
                        <span>PySpark</span>
                        <span>SQL</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-database"></i>
                    </div>
                    <h3>Data Integration for Master Data Management</h3>
                    <p>Led a transformative project creating a versatile data processing system designed to make data management seamless and comprehensive.</p>
                    <div class="project-tech">
                        <span>Data Integration</span>
                        <span>Master Data</span>
                        <span>Data Processing</span>
                        <span>AWS</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-cogs"></i>
                    </div>
                    <h3>Configurable Data Processing & Transformation</h3>
                    <p>Led pivotal project with AWS EMR and Spark pipeline, offering unparalleled flexibility and automation. Included Veeva Vault API integration for pharmaceutical operations.</p>
                    <div class="project-tech">
                        <span>Data Lakes</span>
                        <span>Apache NiFi</span>
                        <span>Python</span>
                        <span>API</span>
                        <span>JSON</span>
                        <span>S3</span>
                        <span>AWS Athena</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-cloud"></i>
                    </div>
                    <h3>Operational Data Lake (ODL)</h3>
                    <p>Revolutionary infrastructure processing data from various pharmaceutical sources including PPD, Syneos, Icon, Parexel, and others for strategic decision-making.</p>
                    <div class="project-tech">
                        <span>Data Lakes</span>
                        <span>Data Integration</span>
                        <span>Apache NiFi</span>
                        <span>Python</span>
                        <span>API</span>
                        <span>JSON</span>
                        <span>S3</span>
                        <span>AWS Athena</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fab fa-microsoft"></i>
                    </div>
                    <h3>SharePoint Online Integration</h3>
                    <p>Led groundbreaking project for pharmaceutical firms, seamlessly extracting data from SharePoint 365 with primary focus on optimizing data flow for protocol deviation management.</p>
                    <div class="project-tech">
                        <span>Data Lakes</span>
                        <span>Data Integration</span>
                        <span>Apache NiFi</span>
                        <span>Python</span>
                        <span>API</span>
                        <span>JSON</span>
                        <span>S3</span>
                        <span>AWS Athena</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-chart-bar"></i>
                    </div>
                    <h3>Healthverity – 16+ TB Data Processing</h3>
                    <p>Spearheaded monumental project overseeing processing of 16 TB of data, showcasing expertise in big data processing and optimization with EMR SPOT instances challenges.</p>
                    <div class="project-tech">
                        <span>Data Lakes</span>
                        <span>Data Integration</span>
                        <span>AWS EMR</span>
                        <span>Airflow</span>
                        <span>S3</span>
                        <span>AWS Athena</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-building"></i>
                    </div>
                    <h3>HBL Datalake Implementation</h3>
                    <p>Engineered robust data pipeline utilizing Sqoop and Spark to efficiently gather data from diverse sources including Core Banking, Mobile Banking, and IRIS systems.</p>
                    <div class="project-tech">
                        <span>Cloudera</span>
                        <span>Apache Hadoop</span>
                        <span>Apache Sqoop</span>
                        <span>Apache Impala</span>
                        <span>Apache Spark</span>
                        <span>ETL</span>
                        <span>Power BI</span>
                        <span>SSRS</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-users-cog"></i>
                    </div>
                    <h3>Active Directory Integration</h3>
                    <p>Established connection to Active Directory through Linked Server, utilizing Microsoft OLE DB Driver for seamless data extraction and enhanced employee management systems.</p>
                    <div class="project-tech">
                        <span>Microsoft SQL Server</span>
                        <span>Linked Server</span>
                        <span>Microsoft OLE DB Driver</span>
                        <span>Active Directory</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-phone"></i>
                    </div>
                    <h3>Call Center Asterisk ETL Pipeline</h3>
                    <p>Led high-impact project developing streamlined ETL pipeline for Asterisk and MySQL-powered call center, providing granular hourly insights into agent performance.</p>
                    <div class="project-tech">
                        <span>MySQL</span>
                        <span>ETL</span>
                        <span>Asterisk</span>
                        <span>SQL Server</span>
                        <span>Linked Server</span>
                    </div>
                </div>
                <div class="project-card">
                    <div class="project-icon">
                        <i class="fas fa-home"></i>
                    </div>
                    <h3>Mortgage Data Warehouse & BI Dashboards</h3>
                    <p>Designed and implemented robust Mortgage Data Warehouse with star schema design, enabling seamless data extraction from BytePro and real-time data access.</p>
                    <div class="project-tech">
                        <span>SQL Server</span>
                        <span>Microsoft SQL Server Agent</span>
                        <span>Linked Server</span>
                        <span>Power BI</span>
                        <span>SSRS</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact" class="contact">
        <div class="container">
            <h2 class="section-title">Get In Touch</h2>
            <div class="contact-content">
                <div class="contact-info">
                    <h3>Let's Connect</h3>
                    <p>I'm always interested in discussing new opportunities and data engineering challenges.</p>
                    <div class="contact-item">
                        <i class="fas fa-envelope"></i>
                        <a href="mailto:Ahmedalam94@outlook.com">Ahmedalam94@outlook.com</a>
                    </div>
                    <div class="contact-item">
                        <i class="fab fa-linkedin"></i>
                        <a href="https://www.linkedin.com/in/ahmedalam94" target="_blank">LinkedIn Profile</a>
                    </div>
                    <div class="contact-item">
                        <i class="fas fa-phone"></i>
                        <a href="tel:+923043765800">+92 304 376 5800</a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Ahmed Alam. All rights reserved.</p>
        </div>
    </footer>

    <!-- JavaScript -->
    <script src="script.js"></script>
</body>
</html>
